{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcskreddy/Hackathon_-2019/blob/master/RAG_Components_Demo\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NOhr7LV7aN7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93dd9823-dbd9-410c-c010-a77e31e1b8d4"
      },
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# Put this at the TOP of your Colab Notebook\n",
        "# ------------------------------------------------------\n",
        "\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# 1. Suppress all warning messages\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 2. Suppress specific libraries' logs (LangChain, OpenAI, FAISS, etc.)\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "logging.getLogger(\"langchain\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"openai\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"faiss\").setLevel(logging.ERROR)\n",
        "\n",
        "# 3. Suppress DeprecationWarnings globally\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "print(\"✅ Warning & log suppression enabled. Notebook will run cleanly.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Warning & log suppression enabled. Notebook will run cleanly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orion is a global company that sells copiers. Orion currently sells ten variants of a copier, with all\n",
        "inventory kept in finished-goods form. The primary component that differentiates the copiers is the\n",
        "printing subassembly. An idea being discussed is to introduce commonality in the printing subassembly\n",
        "so that final assembly can be postponed and inventories kept in component form.\n",
        "Currently, each copier costs $ 1,000 in terms of components. Introducing commonality in the print\n",
        "subassembly will increase component costs to $ 1,025. One of the ten variants represents 80 percent of\n",
        "the total demand. Weekly demand for this variant is normally distributed, with a mean of 1,000 and a\n",
        "standard deviation of 200.\n",
        "Each of the remaining nine variants has a weekly demand of 28 with a standard deviation of 20. Orion\n",
        "aims to provide a 95 percent level of service. Replenishment lead time for components is four weeks.\n",
        "Copier assembly can be completed in a matter of hours. Orion manages all inventories using a\n",
        "continuous review policy and uses a holding cost of 20 percent.\n",
        "1. How much safety inventory of each variant must Orion keep without component commonality?\n",
        "2. What is the annual holding cost?\n",
        "3. How much safety inventory must be kept in component form if Orion uses common components\n",
        "for all variants?\n",
        "4. What is the increase in component cost using commonality is commonality justified across all\n",
        "variants?\n",
        "5. At what cost of commonality will complete commonality be justified?\n",
        "6. Now consider the case in which Orion uses component commonality for only the nine lowdemand variants. How much reduction in safety inventory does Orion achieve in this case?\n",
        "7. What are the savings in terms of annual holding cost is this more restricted form of commonality\n",
        "justified?\n",
        "8. At what cost of commonality will commonality across the low-volume variants be justified?"
      ],
      "metadata": {
        "id": "YJksithxT9U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pypdf\n",
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "_HNcp4u7UNQO",
        "outputId": "b8937b79-916c-48d1-d486-60997036929e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.16)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.75)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.16)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orion is a global company that sells copiers. Orion currently sells ten variants of a copier, with all\n",
        "inventory kept in finished-goods form. The primary component that differentiates the copiers is the\n",
        "printing subassembly. An idea being discussed is to introduce commonality in the printing subassembly\n",
        "so that final assembly can be postponed and inventories kept in component form.\n",
        "Currently, each copier costs $ 1,000 in terms of components. Introducing commonality in the print\n",
        "subassembly will increase component costs to $ 1,025. One of the ten variants represents 80 percent of\n",
        "the total demand. Weekly demand for this variant is normally distributed, with a mean of 1,000 and a\n",
        "standard deviation of 200.\n",
        "Each of the remaining nine variants has a weekly demand of 28 with a standard deviation of 20. Orion\n",
        "aims to provide a 95 percent level of service. Replenishment lead time for components is four weeks.\n",
        "Copier assembly can be completed in a matter of hours. Orion manages all inventories using a\n",
        "continuous review policy and uses a holding cost of 20 percent.\n",
        "1. How much safety inventory of each variant must Orion keep without component commonality?\n",
        "2. What is the annual holding cost?\n",
        "3. How much safety inventory must be kept in component form if Orion uses common components\n",
        "for all variants?\n",
        "4. What is the increase in component cost using commonality is commonality justified across all\n",
        "variants?\n",
        "5. At what cost of commonality will complete commonality be justified?\n",
        "6. Now consider the case in which Orion uses component commonality for only the nine lowdemand variants. How much reduction in safety inventory does Orion achieve in this case?\n",
        "7. What are the savings in terms of annual holding cost is this more restricted form of commonality\n",
        "justified?\n",
        "8. At what cost of commonality will commonality across the low-volume variants be justified?"
      ],
      "metadata": {
        "id": "pgOe3zsVUccC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pypdf\n",
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "LoZT-muiUhTl",
        "outputId": "b392cb19-2c94-451e-bbbb-8dcefc8bf5cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.16)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.75)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.16)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0ZqUTZvuUawY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eUO_sJScUQQs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCk4ZePjahZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84503e6f-4be4-48d5-c280-69782014a8f3"
      },
      "cell_type": "code",
      "source": [
        "# STEP 2\n",
        "# In this step we import the libraries needed to import files from google drive\n",
        "\n",
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "E: Package 'module-init-tools' has no installation candidate\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 126371 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.32-0ubuntu5~bpo22.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.32-0ubuntu5~bpo22.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.32-0ubuntu5~bpo22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8NY8BXJsasz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "cb1d2758-de64-4d4d-9a53-b9d96eb4c322"
      },
      "cell_type": "code",
      "source": [
        "# STEP 3\n",
        "# Generate auth tokens for Colab\n",
        "\n",
        "# CLICK THE LINK GENERATED THEN COPY AND PASTE THE KEY INTO THE FIELD AND CLICK ENTER\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3715316262.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# CLICK THE LINK GENERATED THEN COPY AND PASTE THE KEY INTO THE FIELD AND CLICK ENTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    261\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dKyexqfnb6Xu"
      },
      "cell_type": "code",
      "source": [
        "# STEP 4\n",
        "# Here we connect to your google drive folder.\n",
        "# You can download sample puppy and rabbit images using this link: https://drive.google.com/drive/folders/1RcWFv-PDtGK4n1JgkAgL77fB-N0I4oMP?usp=sharing\n",
        "\n",
        "# WARNING YOU MAY NEED TO RUN THIS CELL MULTIPLE TIMES TO GET A CONNECTION + KEY ESTABLISHED to your google drive.\n",
        "\n",
        "# CLICK THE 1st LINK GENERATED THEN COPY AND PASTE THE KEY INTO THE FIELD AND CLICK ENTER\n",
        "\n",
        "# RE-RUN THIS CELL AND CLICK THE 2nd LINK GENERATED THEN COPY AND PASTE THE KEY INTO THE FIELD AND CLICK ENTER\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "vcode = getpass.getpass()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEC-Jv6ucO0h"
      },
      "cell_type": "code",
      "source": [
        "# STEP 5\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "# print 'Files in Drive:'\n",
        "!ls drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2luJa4dHcXNw"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "print('okay')\n",
        "json_data=open('drive/train.json').read()\n",
        "print('cool')\n",
        "data = json.loads(json_data)\n",
        "print('done')\n",
        "print('removed extraneous data')\n",
        "urls = [obj['url'] for obj in data['images']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JeQ5n_MUcfg2"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from itertools import chain, repeat, cycle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen\n",
        "\n",
        "\n",
        "\n",
        "TARGET_SIZE = (256, 256)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "print('meh')\n",
        "output = []\n",
        "for dat in data['annotations']:\n",
        "  temp = [0]*228\n",
        "  for obj in dat['labelId']:\n",
        "    temp[int(obj)-1] = 1\n",
        "  output.append(temp)\n",
        "depvar = np.array(output)\n",
        "\n",
        "\n",
        "\n",
        "import threading\n",
        "print('mmmmmm donuts')\n",
        "class BatchGenerator:\n",
        "\n",
        "    def __init__(self, batch_size=32,target_size=(256,256)):\n",
        "        self.batch_size = batch_size\n",
        "        self.lock = threading.Lock()\n",
        "        self.TARGET_SIZE=target_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with self.lock:\n",
        "            while True:\n",
        "                X=[]\n",
        "                y=[]\n",
        "                for i in range(32):\n",
        "                    pic = np.random.randint(0,len(urls))\n",
        "                    tempnames = depvar[pic].reshape(1,228)\n",
        "                    try:\n",
        "                        img_file = urlopen(urls[pic])\n",
        "                        im = Image.open(img_file)\n",
        "                    except:\n",
        "                        output = [1]*(256*256*3)\n",
        "                        output = np.array(output).reshape(256,256,3).astype('uint8')\n",
        "                        im = Image.fromarray(output).convert('RGB')\n",
        "                    im2 = im.resize(self.TARGET_SIZE, Image.ANTIALIAS)\n",
        "                    im2.thumbnail(self.TARGET_SIZE, Image.ANTIALIAS)\n",
        "                    #plt.imshow(np.asarray(im2))\n",
        "                    #plt.show()\n",
        "\n",
        "                    X_batch = np.asarray(im2).reshape(1,256,256,3)\n",
        "                    names = depvar[pic]\n",
        "    #                if np.random.rand()>1:\n",
        "    #                    zoomed = np.asarray(im2.resize((512,512), Image.ANTIALIAS))\n",
        "    #                    choice = np.random.randint(0,256)\n",
        "    #                    #choice = 128\n",
        "    #                    X_batch = zoomed[choice:choice+256,choice:choice+256,:].reshape(1,256,256,3)\n",
        "    #                if np.random.rand()>1:\n",
        "    #                    X_batch = X_batch[:,::-1,:,:]\n",
        "                    names.reshape(1,228)\n",
        "                    X_batch = X_batch/255.0\n",
        "                    X.append(X_batch)\n",
        "                    y.append(names)\n",
        "                return np.array(X).reshape(32,256,256,3), np.array(y).reshape(32,228)\n",
        "    def next(self):\n",
        "      return self.__next__()\n",
        "\n",
        "print('check')\n",
        "\n",
        "train_gen = BatchGenerator(batch_size=1631)\n",
        "val_gen = BatchGenerator()\n",
        "#print(train_gen.next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nekK0F_edGWi"
      },
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from PIL import Image\n",
        "def convert_pic_to_array(url):\n",
        "    size = (256, 256)\n",
        "    try:\n",
        "        print('pullimg')\n",
        "        img_file = urlopen(url)\n",
        "        print('imgopen')\n",
        "        im = Image.open(img_file)\n",
        "        print('gothere')\n",
        "    except:\n",
        "        output = [0]*(256*256*3)\n",
        "        output = np.array(output).reshape(1,256,256,3)\n",
        "        return(output)\n",
        "\n",
        "    im2 = im.resize(size, Image.ANTIALIAS)\n",
        "    im2.thumbnail(size, Image.ANTIALIAS)\n",
        "    output = np.asarray(im2)\n",
        "    #print(conv_base.predict(output.reshape(1,256,256,3)).shape)\n",
        "    return(output.reshape(1,256,256,3))\n",
        "convert_pic_to_array(urls[0])\n",
        "urlopen(urls[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhjWhFVGciBP"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.optimizers import SGD,Adamax,Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "#from keras.applications import VGG19\n",
        "\n",
        "def discriminator_model():\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16,\n",
        "                     (6, 6),\n",
        "                     strides=(2,2),\n",
        "                     input_shape=( 256, 256, 3),\n",
        "                     kernel_initializer='glorot_normal',\n",
        "                     bias_initializer='zeros',\n",
        "                     activation='relu'))\n",
        "    #model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(16, (6, 6), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(Conv2D(16, (6, 6), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(Conv2D(16, (6, 6), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(Conv2D(64, (5, 5), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(64, (5, 5), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(Conv2D(64, (5, 5), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(Conv2D(64, (5, 5), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    #model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='glorot_normal'))\n",
        "\n",
        "   # model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(Conv2D(512, (5, 5), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(Conv2D(1024, (5, 5), activation='relu',kernel_initializer='glorot_normal'))\n",
        "  #  model.add(BatchNormalization())\n",
        "    #model.add(Conv2D(2048, (5, 5), activation='relu',kernel_initializer='glorot_normal'))\n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Dense(228,activation='sigmoid',kernel_initializer='glorot_normal'))\n",
        "    return model\n",
        "d = discriminator_model()\n",
        "d_optim = Adam(clipnorm=0.10)\n",
        "d.compile(loss='categorical_crossentropy', optimizer=d_optim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LnJW9FPTbbQM"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.optimizers import SGD,Adamax\n",
        "d = load_model('drive/model.h5')\n",
        "d.load_weights('drive/model_weights.h5')\n",
        "print(d.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKlik1Oydwpq"
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import RMSprop, Adam\n",
        "#from keras.callbacks import ModelCheckpoint\n",
        "d_optim = Adam(lr=0.00001, clipnorm=0.9)\n",
        "d.compile(loss='categorical_crossentropy', optimizer=d_optim)\n",
        "#d_optim = RMSprop(lr=0.00001, clipnorm=0.5)\n",
        "#d.compile(loss='categorical_crossentropy', optimizer=d_optim)\n",
        "#cweights = {}\n",
        "#cw = 1/(np.sum(depvar,axis=0)/np.sum(depvar))\n",
        "#for i in range(len(depvar[0])):\n",
        "#    cweights[i] = cw[i]\n",
        "\n",
        "\n",
        "train_gen = BatchGenerator(batch_size=32)\n",
        "#for i in range(1000):\n",
        "x,y = next(train_gen)\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('drive/model_weights.h5')\n",
        "callbacks_list = [checkpoint]\n",
        "#if i%4==0:\n",
        "d.save_weights('drive/model_weights.h5')\n",
        "history = d.fit_generator(train_gen,steps_per_epoch=250,epochs=110,callbacks=callbacks_list,workers=5,use_multiprocessing=True)#, validation_data=val_gen,validation_steps=1)\n",
        "#else:\n",
        "#d.fit(x,y,epochs=10)\n",
        "d.save('drive/model.h5')\n",
        "d.save_weights('drive/model_weights.h5')\n",
        "test = d.predict(convert_pic_to_array(urls[0]))\n",
        "li = {}\n",
        "for i in range(len(test[0])):\n",
        "    li[i+1]=test[0,i]\n",
        "print(sorted(li.items(), key=lambda x: x[1], reverse=True))\n",
        "print(data['annotations'][0]['labelId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "632KAwIXz5s8"
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "x1,y1 = next(train_gen)\n",
        "inp = d.input                                           # input placeholder                                       # input placeholder\n",
        "outputs = d.layers[0].output\n",
        "functors = K.function([inp], [outputs])\n",
        "s = functors([x1])[0].shape\n",
        "print(s)\n",
        "arr = functors([x1])[0].reshape(s)\n",
        "\n",
        "p = ((255./(np.max(arr[5])-np.min(arr[5])))*(arr[5]-np.min(arr[5])))\n",
        "#p=255.0*arr[i,:,:,2]\n",
        "print(p.shape)\n",
        "fig, ax=plt.subplots(dpi=300)\n",
        "ax.imshow(p.reshape(s[1], s[2]*s[3],order='F'))\n",
        "ax.grid (False)\n",
        "plt.show()\n",
        "plt.imshow(x1[5])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kcsYHdQYV5eq"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}